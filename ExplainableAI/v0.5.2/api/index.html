<!DOCTYPE html><HTML lang="en"><head><script charset="utf-8" src="../../../assets/default/multidoc_injector.js" type="text/javascript"></script><script charset="utf-8" type="text/javascript">window.MULTIDOCUMENTER_ROOT_PATH = '/XAIDocs/'</script><script charset="utf-8" src="../../../assets/default/flexsearch.bundle.js" type="text/javascript"></script><script charset="utf-8" src="../../../assets/default/flexsearch_integration.js" type="text/javascript"></script><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>API Reference · ExplainableAI.jl</title><script data-outdated-warner="" src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script data-main="../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../assets/themeswap.js"></script><link href="https://julia-xai.github.io/XAIDocs/ExplainableAI/stable/api/" rel="canonical"/><link href="../../../assets/default/multidoc.css" rel="stylesheet" type="text/css"/><link href="../../../assets/default/flexsearch.css" rel="stylesheet" type="text/css"/></head><body><nav id="multi-page-nav"><div class="hidden-on-mobile" id="nav-items"><a class="nav-link nav-item" href="../../../XAIDocs/">Getting Started</a><div class="nav-dropdown"><button class="nav-item dropdown-label">Methods</button><ul class="nav-dropdown-container"><a class="nav-link active nav-item" href="../../">ExplainableAI.jl</a><a class="nav-link nav-item" href="../../../RelevancePropagation/">RelevancePropagation.jl</a></ul></div><div class="nav-dropdown"><button class="nav-item dropdown-label">Heatmapping</button><ul class="nav-dropdown-container"><a class="nav-link nav-item" href="../../../VisionHeatmaps/">VisionHeatmaps.jl</a><a class="nav-link nav-item" href="../../../TextHeatmaps/">TextHeatmaps.jl</a></ul></div><a class="nav-link nav-item" href="../../../XAIBase/">Interface</a><div class="search nav-item"><input id="search-input" placeholder="Search everywhere..."/><ul class="suggestions hidden" id="search-result-container"></ul><div class="search-keybinding">/</div></div></div><button id="multidoc-toggler"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg></button></nav><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img alt="ExplainableAI.jl logo" src="../assets/logo.png"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">ExplainableAI.jl</a></span></div><form action="../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../generated/example/">Getting started</a></li><li><a class="tocitem" href="../generated/advanced_lrp/">Advanced LRP</a></li><li class="is-active"><a class="tocitem" href="">API Reference</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Analyzers"><span>Analyzers</span></a></li><li class="toplevel"><a class="tocitem" href="#LRP"><span>LRP</span></a></li><li><a class="tocitem" href="#Rules"><span>Rules</span></a></li><li><a class="tocitem" href="#Custom-rules"><span>Custom rules</span></a></li><li class="toplevel"><a class="tocitem" href="#Utilities"><span>Utilities</span></a></li><li class="toplevel"><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="">API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/adrhill/ExplainableAI.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="Basics"><a class="docs-heading-anchor" href="#Basics">Basics</a><a id="Basics-1"></a><a class="docs-heading-anchor-permalink" href="#Basics" title="Permalink"></a></h1><p>All methods in ExplainableAI.jl work by calling <code>analyze</code> on an input and an analyzer:</p><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.analyze" id="ExplainableAI.analyze"><code>ExplainableAI.analyze</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">analyze(input, method)
analyze(input, method, neuron_selection)</code></pre><p>Return raw classifier output and explanation. If <code>neuron_selection</code> is specified, the explanation will be calculated for that neuron. Otherwise, the output neuron with the highest activation is automatically chosen.</p><p><strong>Keyword arguments</strong></p><ul><li><code>add_batch_dim</code>: add batch dimension to the input without allocating. Default is <code>false</code>.</li></ul></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/analyze_api.jl#L10-L20" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.heatmap" id="ExplainableAI.heatmap"><code>ExplainableAI.heatmap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">heatmap(expl::Explanation; kwargs...)
heatmap(attr::AbstractArray; kwargs...)

heatmap(input, analyzer::AbstractXAIMethod)
heatmap(input, analyzer::AbstractXAIMethod, neuron_selection::Int)</code></pre><p>Visualize explanation. Assumes Flux's WHCN convention (width, height, color channels, batch size).</p><p><strong>Keyword arguments</strong></p><ul><li><code>cs::ColorScheme</code>: ColorScheme that is applied.   When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default is <code>ColorSchemes.seismic</code>.</li><li><code>reduce::Symbol</code>: How the color channels are reduced to a single number to apply a colorscheme.   The following methods can be selected, which are then applied over the color channels   for each "pixel" in the attribution:<ul><li><code>:sum</code>: sum up color channels</li><li><code>:norm</code>: compute 2-norm over the color channels</li><li><code>:maxabs</code>: compute <code>maximum(abs, x)</code> over the color channels in</li></ul>When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default is <code>:sum</code>.</li><li><code>rangescale::Symbol</code>: How the color channel reduced heatmap is normalized before the colorscheme is applied.   Can be either <code>:extrema</code> or <code>:centered</code>.   When calling <code>heatmap</code> with an <code>Explanation</code> or analyzer, the method default is selected.   When calling <code>heatmap</code> with an array, the default for use with the <code>seismic</code> colorscheme is <code>:centered</code>.</li><li><code>permute::Bool</code>: Whether to flip W&amp;H input channels. Default is <code>true</code>.</li><li><code>unpack_singleton::Bool</code>: When heatmapping a batch with a single sample, setting <code>unpack_singleton=true</code>   will return an image instead of an Vector containing a single image.</li></ul><p><strong>Note:</strong> these keyword arguments can't be used when calling <code>heatmap</code> with an analyzer.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/heatmap.jl#L10-L41" target="_blank">source</a></section></article><h1 id="Analyzers"><a class="docs-heading-anchor" href="#Analyzers">Analyzers</a><a id="Analyzers-1"></a><a class="docs-heading-anchor-permalink" href="#Analyzers" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.LRP" id="ExplainableAI.LRP"><code>ExplainableAI.LRP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LRP(c::Chain, r::AbstractLRPRule)
LRP(c::Chain, rs::AbstractVector{&lt;:AbstractLRPRule})</code></pre><p>Analyze model by applying Layer-Wise Relevance Propagation.</p><p><strong>Keyword arguments</strong></p><ul><li><code>skip_checks::Bool</code>: Skip checks whether model is compatible with LRP and contains output softmax. Default is <code>false</code>.</li><li><code>verbose::Bool</code>: Select whether the model checks should print a summary on failure. Default is <code>true</code>.</li></ul><p><strong>References</strong></p><p>[1] G. Montavon et al., Layer-Wise Relevance Propagation: An Overview [2] W. Samek et al., Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/lrp.jl#L1-L14" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.Gradient" id="ExplainableAI.Gradient"><code>ExplainableAI.Gradient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Gradient(model)</code></pre><p>Analyze model by calculating the gradient of a neuron activation with respect to the input.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/gradient.jl#L18-L22" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.InputTimesGradient" id="ExplainableAI.InputTimesGradient"><code>ExplainableAI.InputTimesGradient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InputTimesGradient(model)</code></pre><p>Analyze model by calculating the gradient of a neuron activation with respect to the input. This gradient is then multiplied element-wise with the input.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/gradient.jl#L34-L39" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.SmoothGrad" id="ExplainableAI.SmoothGrad"><code>ExplainableAI.SmoothGrad</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SmoothGrad(analyzer, [n=50, std=0.1, rng=GLOBAL_RNG])
SmoothGrad(analyzer, [n=50, distribution=Normal(0, σ²=0.01), rng=GLOBAL_RNG])</code></pre><p>Analyze model by calculating a smoothed sensitivity map. This is done by averaging sensitivity maps of a <code>Gradient</code> analyzer over random samples in a neighborhood of the input, typically by adding Gaussian noise with mean 0.</p><p><strong>References</strong></p><p>[1] Smilkov et al., SmoothGrad: removing noise by adding noise</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/gradient.jl#L53-L63" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.IntegratedGradients" id="ExplainableAI.IntegratedGradients"><code>ExplainableAI.IntegratedGradients</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">IntegratedGradients(analyzer, [n=50])
IntegratedGradients(analyzer, [n=50])</code></pre><p>Analyze model by using the Integrated Gradients method.</p><p><strong>References</strong></p><p>[1] Sundararajan et al., Axiomatic Attribution for Deep Networks</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/gradient.jl#L66-L74" target="_blank">source</a></section></article><p><code>SmoothGrad</code> and <code>IntegratedGradients</code> are special cases of the input augmentation wrappers <code>NoiseAugmentation</code> and <code>InterpolationAugmentation</code>, which can be applied as a wrapper to any analyzer:</p><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.NoiseAugmentation" id="ExplainableAI.NoiseAugmentation"><code>ExplainableAI.NoiseAugmentation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NoiseAugmentation(analyzer, n, [std=1, rng=GLOBAL_RNG])
NoiseAugmentation(analyzer, n, distribution, [rng=GLOBAL_RNG])</code></pre><p>A wrapper around analyzers that augments the input with <code>n</code> samples of additive noise sampled from <code>distribution</code>. This input augmentation is then averaged to return an <code>Explanation</code>.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/input_augmentation.jl#L75-L81" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.InterpolationAugmentation" id="ExplainableAI.InterpolationAugmentation"><code>ExplainableAI.InterpolationAugmentation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InterpolationAugmentation(model, [n=50])</code></pre><p>A wrapper around analyzers that augments the input with <code>n</code> steps of linear interpolation between the input and a reference input (typically <code>zero(input)</code>). The gradients w.r.t. this augmented input are then averaged and multiplied with the difference between the input and the reference input.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/input_augmentation.jl#L120-L127" target="_blank">source</a></section></article><h1 id="LRP"><a class="docs-heading-anchor" href="#LRP">LRP</a><a id="LRP-1"></a><a class="docs-heading-anchor-permalink" href="#LRP" title="Permalink"></a></h1><h2 id="Rules"><a class="docs-heading-anchor" href="#Rules">Rules</a><a id="Rules-1"></a><a class="docs-heading-anchor-permalink" href="#Rules" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.ZeroRule" id="ExplainableAI.ZeroRule"><code>ExplainableAI.ZeroRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZeroRule()</code></pre><p>LRP-0 rule. Commonly used on upper layers.</p><p><strong>References</strong></p><p>[1]: S. Bach et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by     Layer-Wise Relevance Propagation</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L106-L114" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.EpsilonRule" id="ExplainableAI.EpsilonRule"><code>ExplainableAI.EpsilonRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">EpsilonRule([ϵ=1.0f-6])</code></pre><p>LRP-<span>$ϵ$</span> rule. Commonly used on middle layers.</p><p>Arguments:</p><ul><li><code>ϵ</code>: Optional stabilization parameter, defaults to <code>1f-6</code>.</li></ul><p><strong>References</strong></p><p>[1]: S. Bach et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by     Layer-Wise Relevance Propagation</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L121-L132" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.GammaRule" id="ExplainableAI.GammaRule"><code>ExplainableAI.GammaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GammaRule([γ=0.25])</code></pre><p>LRP-<span>$γ$</span> rule. Commonly used on lower layers.</p><p>Arguments:</p><ul><li><code>γ</code>: Optional multiplier for added positive weights, defaults to <code>0.25</code>.</li></ul><p><strong>References</strong></p><p>[1]: G. Montavon et al., Layer-Wise Relevance Propagation: An Overview</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L143-L153" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.WSquareRule" id="ExplainableAI.WSquareRule"><code>ExplainableAI.WSquareRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WSquareRule()</code></pre><p>LRP-<span>$W^2$</span> rule. Commonly used on the first layer when values are unbounded.</p><p><strong>References</strong></p><p>[1]: G. Montavon et al., Explaining nonlinear classification decisions with deep Taylor decomposition</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L164-L171" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.AlphaBetaRule" id="ExplainableAI.AlphaBetaRule"><code>ExplainableAI.AlphaBetaRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AlphaBetaRule(alpha, beta)
AlphaBetaRule([alpha=2.0], [beta=1.0])</code></pre><p>LRP-<span>$�lpha�eta$</span> rule. Weights positive and negative contributions according to the parameters <code>alpha</code> and <code>beta</code> respectively. The difference <code>alpha - beta</code> must be equal one. Commonly used on lower layers.</p><p>Arguments:</p><ul><li><code>alpha</code>: Multiplier for the positive output term, defaults to <code>2.0</code>.</li><li><code>beta</code>: Multiplier for the negative output term, defaults to <code>1.0</code>.</li></ul><p><strong>References</strong></p><p>[1]: S. Bach et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by     Layer-Wise Relevance Propagation [2]: G. Montavon et al., Layer-Wise Relevance Propagation: An Overview</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L254-L270" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.FlatRule" id="ExplainableAI.FlatRule"><code>ExplainableAI.FlatRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FlatRule()</code></pre><p>LRP-Flat rule. Similar to the <a href="#ExplainableAI.WSquareRule"><code>WSquareRule</code></a>, but with all parameters set to one.</p><p><strong>References</strong></p><p>[1]: S. Lapuschkin et al., Unmasking Clever Hans predictors and assessing what machines really learn</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L176-L183" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.ZBoxRule" id="ExplainableAI.ZBoxRule"><code>ExplainableAI.ZBoxRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZBoxRule(low, high)</code></pre><p>LRP-<span>$z^{\mathcal{B}}$</span>-rule. Commonly used on the first layer for pixel input.</p><p>The parameters <code>low</code> and <code>high</code> should be set to the lower and upper bounds of the input features, e.g. <code>0.0</code> and <code>1.0</code> for raw image data. It is also possible to provide two arrays of that match the input size.</p><p><strong>References</strong></p><p>[1]: G. Montavon et al., Explaining nonlinear classification decisions with deep Taylor decomposition</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L205-L216" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.PassRule" id="ExplainableAI.PassRule"><code>ExplainableAI.PassRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PassRule()</code></pre><p>Pass-through rule. Passes relevance through to the lower layer. Supports reshaping layers.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L188-L193" target="_blank">source</a></section></article><h2 id="Custom-rules"><a class="docs-heading-anchor" href="#Custom-rules">Custom rules</a><a id="Custom-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-rules" title="Permalink"></a></h2><p>These utilities can be used to define custom rules without writing boilerplate code:</p><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.modify_input" id="ExplainableAI.modify_input"><code>ExplainableAI.modify_input</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_input(rule, input)</code></pre><p>Modify input activation before computing relevance propagation.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L24-L28" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.modify_denominator" id="ExplainableAI.modify_denominator"><code>ExplainableAI.modify_denominator</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_denominator(rule, d)</code></pre><p>Modify denominator <span>$z$</span> for numerical stability on the forward pass.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L31-L35" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.modify_param!" id="ExplainableAI.modify_param!"><code>ExplainableAI.modify_param!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_param!(rule, W)
modify_param!(rule, b)</code></pre><p>Inplace-modify parameters before computing the relevance.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L73-L78" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.modify_layer!" id="ExplainableAI.modify_layer!"><code>ExplainableAI.modify_layer!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">modify_layer!(rule, layer; ignore_bias=false)</code></pre><p>In-place modify layer parameters by calling <code>modify_param!</code> before computing relevance propagation.</p><p><strong>Note</strong></p><p>When implementing a custom <code>modify_layer!</code> function, <code>modify_param!</code> will not be called.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/rules.jl#L49-L57" target="_blank">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>check_compat</code>. Check Documenter's build log for details.</p></div></div><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.LRP_CONFIG.supports_layer" id="ExplainableAI.LRP_CONFIG.supports_layer"><code>ExplainableAI.LRP_CONFIG.supports_layer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(layer)</code></pre><p>Check whether LRP can be used on a layer or a Chain. To extend LRP to your own layers, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_layer(::MyLayer) = true          # for structs
LRP_CONFIG.supports_layer(::typeof(mylayer)) = true  # for functions</code></pre></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/checks.jl#L4-L13" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.LRP_CONFIG.supports_activation" id="ExplainableAI.LRP_CONFIG.supports_activation"><code>ExplainableAI.LRP_CONFIG.supports_activation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(σ)</code></pre><p>Check whether LRP can be used on a given activation function. To extend LRP to your own activation functions, define:</p><pre><code class="language-julia hljs">LRP_CONFIG.supports_activation(::typeof(myactivation)) = true  # for functions
LRP_CONFIG.supports_activation(::MyActivation) = true          # for structs</code></pre></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/checks.jl#L16-L25" target="_blank">source</a></section></article><h1 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.strip_softmax" id="ExplainableAI.strip_softmax"><code>ExplainableAI.strip_softmax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">strip_softmax(model)</code></pre><p>Remove softmax activation on model output if it exists.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/flux_utils.jl#L47-L51" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.flatten_model" id="ExplainableAI.flatten_model"><code>ExplainableAI.flatten_model</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">flatten_model(c)</code></pre><p>Flatten a Flux chain containing Flux chains.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/flux_utils.jl#L12-L16" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#ExplainableAI.canonize" id="ExplainableAI.canonize"><code>ExplainableAI.canonize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">canonize(model)</code></pre><p>Canonize model by flattening it and fusing BatchNorm layers into preceding Dense and Conv layers with linear activation functions.</p></div><a class="docs-sourcelink" href="https://github.com/adrhill/ExplainableAI.jl/blob/5afd2606b8fb3fc1a23b9628138f5b311b266561/src/lrp/canonize.jl#L37-L42" target="_blank">source</a></section></article><h1 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h1><ul><li><a href="#ExplainableAI.AlphaBetaRule"><code>ExplainableAI.AlphaBetaRule</code></a></li><li><a href="#ExplainableAI.EpsilonRule"><code>ExplainableAI.EpsilonRule</code></a></li><li><a href="#ExplainableAI.FlatRule"><code>ExplainableAI.FlatRule</code></a></li><li><a href="#ExplainableAI.GammaRule"><code>ExplainableAI.GammaRule</code></a></li><li><a href="#ExplainableAI.Gradient"><code>ExplainableAI.Gradient</code></a></li><li><a href="#ExplainableAI.InputTimesGradient"><code>ExplainableAI.InputTimesGradient</code></a></li><li><a href="#ExplainableAI.InterpolationAugmentation"><code>ExplainableAI.InterpolationAugmentation</code></a></li><li><a href="#ExplainableAI.LRP"><code>ExplainableAI.LRP</code></a></li><li><a href="#ExplainableAI.NoiseAugmentation"><code>ExplainableAI.NoiseAugmentation</code></a></li><li><a href="#ExplainableAI.PassRule"><code>ExplainableAI.PassRule</code></a></li><li><a href="#ExplainableAI.WSquareRule"><code>ExplainableAI.WSquareRule</code></a></li><li><a href="#ExplainableAI.ZBoxRule"><code>ExplainableAI.ZBoxRule</code></a></li><li><a href="#ExplainableAI.ZeroRule"><code>ExplainableAI.ZeroRule</code></a></li><li><a href="#ExplainableAI.IntegratedGradients"><code>ExplainableAI.IntegratedGradients</code></a></li><li><a href="#ExplainableAI.LRP_CONFIG.supports_activation"><code>ExplainableAI.LRP_CONFIG.supports_activation</code></a></li><li><a href="#ExplainableAI.LRP_CONFIG.supports_layer"><code>ExplainableAI.LRP_CONFIG.supports_layer</code></a></li><li><a href="#ExplainableAI.SmoothGrad"><code>ExplainableAI.SmoothGrad</code></a></li><li><a href="#ExplainableAI.analyze"><code>ExplainableAI.analyze</code></a></li><li><a href="#ExplainableAI.canonize"><code>ExplainableAI.canonize</code></a></li><li><a href="#ExplainableAI.flatten_model"><code>ExplainableAI.flatten_model</code></a></li><li><a href="#ExplainableAI.heatmap"><code>ExplainableAI.heatmap</code></a></li><li><a href="#ExplainableAI.modify_denominator"><code>ExplainableAI.modify_denominator</code></a></li><li><a href="#ExplainableAI.modify_input"><code>ExplainableAI.modify_input</code></a></li><li><a href="#ExplainableAI.modify_layer!"><code>ExplainableAI.modify_layer!</code></a></li><li><a href="#ExplainableAI.modify_param!"><code>ExplainableAI.modify_param!</code></a></li><li><a href="#ExplainableAI.strip_softmax"><code>ExplainableAI.strip_softmax</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../generated/advanced_lrp/">« Advanced LRP</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Friday 5 August 2022 13:25">Friday 5 August 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>