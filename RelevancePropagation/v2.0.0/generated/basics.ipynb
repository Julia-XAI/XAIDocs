{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating an LRP Analyzer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start out by loading a small convolutional neural network:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using RelevancePropagation\n",
    "using Flux\n",
    "\n",
    "model = Chain(\n",
    "    Chain(\n",
    "        Conv((3, 3), 3 => 8, relu; pad=1),\n",
    "        Conv((3, 3), 8 => 8, relu; pad=1),\n",
    "        MaxPool((2, 2)),\n",
    "        Conv((3, 3), 8 => 16; pad=1),\n",
    "        BatchNorm(16, relu),\n",
    "        Conv((3, 3), 16 => 8, relu; pad=1),\n",
    "        BatchNorm(8, relu),\n",
    "    ),\n",
    "    Chain(Flux.flatten, Dense(2048 => 512, relu), Dropout(0.5), Dense(512 => 100, softmax)),\n",
    ");"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "This model contains two chains: the convolutional layers and the fully connected layers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stripping the output softmax\n",
    "When using LRP, it is recommended to explain output logits instead of probabilities.\n",
    "This can be done by stripping the output softmax activation from the model\n",
    "using the `strip_softmax` function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(\n  Chain(\n    Conv((3, 3), 3 => 8, relu, pad=1),  \u001b[90m# 224 parameters\u001b[39m\n    Conv((3, 3), 8 => 8, relu, pad=1),  \u001b[90m# 584 parameters\u001b[39m\n    MaxPool((2, 2)),\n    Conv((3, 3), 8 => 16, pad=1),       \u001b[90m# 1_168 parameters\u001b[39m\n    BatchNorm(16, relu),                \u001b[90m# 32 parameters\u001b[39m\u001b[90m, plus 32\u001b[39m\n    Conv((3, 3), 16 => 8, relu, pad=1),  \u001b[90m# 1_160 parameters\u001b[39m\n    BatchNorm(8, relu),                 \u001b[90m# 16 parameters\u001b[39m\u001b[90m, plus 16\u001b[39m\n  ),\n  Chain(\n    Flux.flatten,\n    Dense(2048 => 512, relu),           \u001b[90m# 1_049_088 parameters\u001b[39m\n    Dropout(0.5),\n    Dense(512 => 100),                  \u001b[90m# 51_300 parameters\u001b[39m\n  ),\n) \u001b[90m        # Total: 16 trainable arrays, \u001b[39m1_103_572 parameters,\n\u001b[90m          # plus 4 non-trainable, 48 parameters, summarysize \u001b[39m4.213 MiB."
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "model = strip_softmax(model)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you don't remove the output softmax,\n",
    "model checks will fail."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model canonization\n",
    "LRP is not invariant to a model's implementation.\n",
    "Applying the `GammaRule` to two linear layers in a row will yield different results\n",
    "than first fusing the two layers into one linear layer and then applying the rule.\n",
    "This fusing is called \"canonization\" and can be done using the `canonize` function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(\n  Conv((3, 3), 3 => 8, relu, pad=1),    \u001b[90m# 224 parameters\u001b[39m\n  Conv((3, 3), 8 => 8, relu, pad=1),    \u001b[90m# 584 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Conv((3, 3), 8 => 16, relu, pad=1),   \u001b[90m# 1_168 parameters\u001b[39m\n  Conv((3, 3), 16 => 8, relu, pad=1),   \u001b[90m# 1_160 parameters\u001b[39m\n  BatchNorm(8, relu),                   \u001b[90m# 16 parameters\u001b[39m\u001b[90m, plus 16\u001b[39m\n  Flux.flatten,\n  Dense(2048 => 512, relu),             \u001b[90m# 1_049_088 parameters\u001b[39m\n  Dropout(0.5),\n  Dense(512 => 100),                    \u001b[90m# 51_300 parameters\u001b[39m\n) \u001b[90m        # Total: 14 trainable arrays, \u001b[39m1_103_540 parameters,\n\u001b[90m          # plus 2 non-trainable, 16 parameters, summarysize \u001b[39m4.212 MiB."
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "model_canonized = canonize(model)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "After canonization, the first `BatchNorm` layer has been fused into the preceding `Conv` layer.\n",
    "The second `BatchNorm` layer wasn't fused\n",
    "since its preceding `Conv` layer has a ReLU activation function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flattening the model\n",
    "RelevancePropagation.jl's LRP implementation supports nested Flux Chains and Parallel layers.\n",
    "However, it is recommended to flatten the model before analyzing it.\n",
    "\n",
    "LRP is implemented by first running a forward pass through the model,\n",
    "keeping track of the intermediate activations, followed by a backward pass\n",
    "that computes the relevances.\n",
    "\n",
    "To keep the LRP implementation simple and maintainable,\n",
    "RelevancePropagation.jl does not pre-compute \"nested\" activations.\n",
    "Instead, for every internal chain, a new forward pass is run to compute activations.\n",
    "\n",
    "By \"flattening\" a model, this overhead can be avoided.\n",
    "For this purpose, RelevancePropagation.jl provides the function `flatten_model`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(\n  Conv((3, 3), 3 => 8, relu, pad=1),    \u001b[90m# 224 parameters\u001b[39m\n  Conv((3, 3), 8 => 8, relu, pad=1),    \u001b[90m# 584 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Conv((3, 3), 8 => 16, pad=1),         \u001b[90m# 1_168 parameters\u001b[39m\n  BatchNorm(16, relu),                  \u001b[90m# 32 parameters\u001b[39m\u001b[90m, plus 32\u001b[39m\n  Conv((3, 3), 16 => 8, relu, pad=1),   \u001b[90m# 1_160 parameters\u001b[39m\n  BatchNorm(8, relu),                   \u001b[90m# 16 parameters\u001b[39m\u001b[90m, plus 16\u001b[39m\n  Flux.flatten,\n  Dense(2048 => 512, relu),             \u001b[90m# 1_049_088 parameters\u001b[39m\n  Dropout(0.5),\n  Dense(512 => 100),                    \u001b[90m# 51_300 parameters\u001b[39m\n) \u001b[90m        # Total: 16 trainable arrays, \u001b[39m1_103_572 parameters,\n\u001b[90m          # plus 4 non-trainable, 48 parameters, summarysize \u001b[39m4.212 MiB."
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "model_flat = flatten_model(model)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function is called by default when creating an LRP analyzer.\n",
    "Note that we pass the unflattened model to the analyzer, but `analyzer.model` is flattened:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(\n  Conv((3, 3), 3 => 8, relu, pad=1),    \u001b[90m# 224 parameters\u001b[39m\n  Conv((3, 3), 8 => 8, relu, pad=1),    \u001b[90m# 584 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Conv((3, 3), 8 => 16, pad=1),         \u001b[90m# 1_168 parameters\u001b[39m\n  BatchNorm(16, relu),                  \u001b[90m# 32 parameters\u001b[39m\u001b[90m, plus 32\u001b[39m\n  Conv((3, 3), 16 => 8, relu, pad=1),   \u001b[90m# 1_160 parameters\u001b[39m\n  BatchNorm(8, relu),                   \u001b[90m# 16 parameters\u001b[39m\u001b[90m, plus 16\u001b[39m\n  Flux.flatten,\n  Dense(2048 => 512, relu),             \u001b[90m# 1_049_088 parameters\u001b[39m\n  Dropout(0.5),\n  Dense(512 => 100),                    \u001b[90m# 51_300 parameters\u001b[39m\n) \u001b[90m        # Total: 16 trainable arrays, \u001b[39m1_103_572 parameters,\n\u001b[90m          # plus 4 non-trainable, 48 parameters, summarysize \u001b[39m4.212 MiB."
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "analyzer = LRP(model)\n",
    "analyzer.model"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "If this flattening is not desired, it can be disabled\n",
    "by passing the keyword argument `flatten=false` to the `LRP` constructor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LRP rules\n",
    "The following examples will be run on a pre-trained LeNet-5 model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Chain(\n  Conv((5, 5), 1 => 6, relu),           \u001b[90m# 156 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Conv((5, 5), 6 => 16, relu),          \u001b[90m# 2_416 parameters\u001b[39m\n  MaxPool((2, 2)),\n  Flux.flatten,\n  Dense(256 => 120, relu),              \u001b[90m# 30_840 parameters\u001b[39m\n  Dense(120 => 84, relu),               \u001b[90m# 10_164 parameters\u001b[39m\n  Dense(84 => 10),                      \u001b[90m# 850 parameters\u001b[39m\n) \u001b[90m                  # Total: 10 arrays, \u001b[39m44_426 parameters, 174.867 KiB."
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "using BSON\n",
    "\n",
    "model = BSON.load(\"../model.bson\", @__MODULE__)[:model] # load pre-trained LeNet-5 model"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also load the MNIST dataset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "28×28 reinterpret(reshape, ColorTypes.Gray{Float32}, ::Matrix{Float32}) with eltype ColorTypes.Gray{Float32}:\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n ⋮                                       ⋱  \n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjhJREFUaAW9wb2L1gUAB/DPcd+oQaPswCGqpSGHXqYTapGgJSg4CeoPcEiECqFDpCGwTdIQImuIsGiTtmjJgl6GoKEiIhqCoMQsOOhFy85r+A3H8fTo73mM7+cTZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWc7gTS1jBHlzGSXyK71xZlEVZlMUM7sYB7MWSrXbjH3yLj/E0/jYpyqIsymKEe3AAj+NGgx/xEb7HKj7HMnbgYXyBkyZFWZRFWVzFq1jBksH7+AqHcdHgfuzH67gP5/AyTuO8raIsyqIsprgBq9iHBZzHKziKP2x1CxbxPN7DHaaLsiiLsphiD57FAn7CXnxmq0XchlN4FzcbLOBNrJkUZVEWZTHFItYNLmE3HsNdBhewC7vwC3badA4v4JJJURZlURZTnMEHeAi34wQ2DNaxaNNOg8t4B0/hrP8WZVEWZTHFBazgJhzCA/gVP+B63ItlW72Gw1gzXZRFWZTFVazhkEmnsGzwGw7iDay7siiLsiiLOaziCZv2423jRFmURVnMaB+eQwy+xmnjRVmURVnMYBkvYpvB73gSfxkvyqIsymIGj2C7wZ94FJ+YTZRFWZTFSNuxatNb+NDsoizKoixG2IZvcJ3Bl3jGfKIsyqIsRngQt2LD4CAumk+URVmUxQhHsGFwFGfML8qiLMpihB1YwM94ybWJsiiLshjhGI7hCM66NlEWZVEWIxzHcf+PKIuyKPsXNwdYfgiRxs8AAAAASUVORK5CYII=",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjhJREFUaAW9wb2L1gUAB/DPcd+oQaPswCGqpSGHXqYTapGgJSg4CeoPcEiECqFDpCGwTdIQImuIsGiTtmjJgl6GoKEiIhqCoMQsOOhFy85r+A3H8fTo73mM7+cTZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWc7gTS1jBHlzGSXyK71xZlEVZlMUM7sYB7MWSrXbjH3yLj/E0/jYpyqIsymKEe3AAj+NGgx/xEb7HKj7HMnbgYXyBkyZFWZRFWVzFq1jBksH7+AqHcdHgfuzH67gP5/AyTuO8raIsyqIsprgBq9iHBZzHKziKP2x1CxbxPN7DHaaLsiiLsphiD57FAn7CXnxmq0XchlN4FzcbLOBNrJkUZVEWZTHFItYNLmE3HsNdBhewC7vwC3badA4v4JJJURZlURZTnMEHeAi34wQ2DNaxaNNOg8t4B0/hrP8WZVEWZTHFBazgJhzCA/gVP+B63ItlW72Gw1gzXZRFWZTFVazhkEmnsGzwGw7iDay7siiLsiiLOaziCZv2423jRFmURVnMaB+eQwy+xmnjRVmURVnMYBkvYpvB73gSfxkvyqIsymIGj2C7wZ94FJ+YTZRFWZTFSNuxatNb+NDsoizKoixG2IZvcJ3Bl3jGfKIsyqIsRngQt2LD4CAumk+URVmUxQhHsGFwFGfML8qiLMpihB1YwM94ybWJsiiLshjhGI7hCM66NlEWZVEWIxzHcf+PKIuyKPsXNwdYfgiRxs8AAAAASUVORK5C\">"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "using MLDatasets\n",
    "using ImageCore, ImageIO, ImageShow\n",
    "\n",
    "index = 10\n",
    "x, y = MNIST(Float32, :test)[10]\n",
    "input = reshape(x, 28, 28, 1, :)\n",
    "\n",
    "convert2image(MNIST, x)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, the `LRP` constructor will assign the `ZeroRule` to all layers."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LRP(\n  Conv((5, 5), 1 => 6, relu) \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  MaxPool((2, 2))            \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Conv((5, 5), 6 => 16, relu)\u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  MaxPool((2, 2))            \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Flux.flatten               \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Dense(256 => 120, relu)    \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Dense(120 => 84, relu)     \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Dense(84 => 10)            \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "analyzer = LRP(model)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "This ana lyzer will return heatmaps that look identical to the `InputTimesGradient` analyzer\n",
    "from [ExplainableAI.jl](https://github.com/Julia-XAI/ExplainableAI.jl).\n",
    "We can visualize `Explanation`s by computing a `heatmap` using either\n",
    "[VisionHeatmaps.jl](https://julia-xai.github.io/XAIDocs/VisionHeatmaps/stable/) or\n",
    "[TextHeatmaps.jl](https://julia-xai.github.io/XAIDocs/TextHeatmaps/stable/),\n",
    "either for images or text, respectively."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "28×28 Array{RGB{Float64},2} with eltype ColorTypes.RGB{Float64}:\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n ⋮                          ⋱  \n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)     RGB{Float64}(1.0,1.0,1.0)",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAABBtJREFUeAHtwU9I1gcYwPGvvk9qv/fVF9KyDpmZoisZlTUK+kMdtkUdIiiD4bGOa4PYYQ62S4Ug/bl06RCd2lrQcK5asGgs6OCCRRtGWYeNDmVbLNNme/Xd6XnsIETy+Po6ns9H8vk8wY8QXAnBlRBcCcGVEFwJwZUQXAnBlRBcCcGVEFwJwZUQXAnBlRBcCcGVEFwJwZUQXAnBlRBcCcGVEFwJwZUQXAnBlRBcCUUsl2NS0vsN5swZTEMDprMT9U8yD1VRwbQSgishuBKCK6EYDA9jRkZQcu8e5tEjzOAgJpXClJZiBgZQFbW1qO9+XYLKZjHr12NSKaZMCK6E4EoIroRCev4cNZTPoO7eTaPaWpjw9CmmtRVz6xZm3z5Mfz/m5EnMqlWoxvcPoOrqMIODmIULmTIhuBKCKyG4EqbZ+Djm+58yqIcPMbdvY+o+S6MyW7ej5paPY5qamFRtLWr8w49Qw8OY5h97MTeeoOaWl2P27MGkUrwJIbgSgishuBK85POYBw9Qv/y9DLVzJ+blS8zly5hsFlNWxitKeZ3DF1ei9lZhkgRTuWED5vp1zKZNmHyeqRKCKyG4EoIrwUlurAT1w8AyVDaLOXIEs3YtZuNG3sj4OGZoCPPpJznMjRuYJEGdu9+GWr58B6q14iUmlWKqhOBKCK6E4EpwIi+GUO/98RXm5Leot3p6UNlLlzDtp1Gj586hyvv6MKdOoUoPHEBlDx3CNDRgVq7EbN6M2lKH6e3FLF5chsqWMWVCcCUEV0JwJXiprMRUVqJGenpQx3nFtm2oUiZkmPBxVxfq6/PnUbuHhjD372NGRzFVVZjmZtT8pXNRHR1plAguhOBKCK6E4EqYDu3tqGT7dtTnu3ZhVqxA/Xv8OGpOYyMmnUbtbmtDjZw9i0q6uzHPnmFyOUxZGSZJUFKCOyG4EoIrIbgSplsmg7lyhcnMOXaM1zpxAvX7zZuolqtXMQ0NmIMHMUuWUChCcCUEV0JwJRSzsTFMTQ2qZfVqTDqN6erCJAkzQQiuhOBKCK6EItPZiTl8+DdU/vG7qJ+bP0CtWYPJ5zElzAwhuBKCKyG4EopAby/m6FHMli1vo7a2Yx4/xly4gGlqYsYJwZUQXAnBlVAEBgcxS5di5s3DtLZiduzANDVRVITgSgiuhOBKmCEvXmCuXcP09w+jqqrSqO5uTH09RUsIroTgSgiuhBnS14fZvx8zOppGrVuHqa9nVhCCKyG4EoIroZAGBlCbKv5CXXzyDurLL+6g/pzfwmwjBFdCcCUEV0IhnT6N6ehAralnQmkNqrqaWUcIroTgSgiuhEJatAizYAEmx4TqamYzIbgSgishuBIKae9ezNgYKkmYUFLCbCYEV0JwJQRXQiHV1DCZDP8fQnAlBFdCcPUfZaDIbeMVzvAAAAAASUVORK5CYII=",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAIAAABJgmMcAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAABBtJREFUeAHtwU9I1gcYwPGvvk9qv/fVF9KyDpmZoisZlTUK+kMdtkUdIiiD4bGOa4PYYQ62S4Ug/bl06RCd2lrQcK5asGgs6OCCRRtGWYeNDmVbLNNme/Xd6XnsIETy+Po6ns9H8vk8wY8QXAnBlRBcCcGVEFwJwZUQXAnBlRBcCcGVEFwJwZUQXAnBlRBcCcGVEFwJwZUQXAnBlRBcCcGVEFwJwZUQXAnBlRBcCUUsl2NS0vsN5swZTEMDprMT9U8yD1VRwbQSgishuBKCK6EYDA9jRkZQcu8e5tEjzOAgJpXClJZiBgZQFbW1qO9+XYLKZjHr12NSKaZMCK6E4EoIroRCev4cNZTPoO7eTaPaWpjw9CmmtRVz6xZm3z5Mfz/m5EnMqlWoxvcPoOrqMIODmIULmTIhuBKCKyG4EqbZ+Djm+58yqIcPMbdvY+o+S6MyW7ej5paPY5qamFRtLWr8w49Qw8OY5h97MTeeoOaWl2P27MGkUrwJIbgSgishuBK85POYBw9Qv/y9DLVzJ+blS8zly5hsFlNWxitKeZ3DF1ei9lZhkgRTuWED5vp1zKZNmHyeqRKCKyG4EoIrwUlurAT1w8AyVDaLOXIEs3YtZuNG3sj4OGZoCPPpJznMjRuYJEGdu9+GWr58B6q14iUmlWKqhOBKCK6E4EpwIi+GUO/98RXm5Leot3p6UNlLlzDtp1Gj586hyvv6MKdOoUoPHEBlDx3CNDRgVq7EbN6M2lKH6e3FLF5chsqWMWVCcCUEV0JwJXiprMRUVqJGenpQx3nFtm2oUiZkmPBxVxfq6/PnUbuHhjD372NGRzFVVZjmZtT8pXNRHR1plAguhOBKCK6E4EqYDu3tqGT7dtTnu3ZhVqxA/Xv8OGpOYyMmnUbtbmtDjZw9i0q6uzHPnmFyOUxZGSZJUFKCOyG4EoIrIbgSplsmg7lyhcnMOXaM1zpxAvX7zZuolqtXMQ0NmIMHMUuWUChCcCUEV0JwJRSzsTFMTQ2qZfVqTDqN6erCJAkzQQiuhOBKCK6EItPZiTl8+DdU/vG7qJ+bP0CtWYPJ5zElzAwhuBKCKyG4EopAby/m6FHMli1vo7a2Yx4/xly4gGlqYsYJwZUQXAnBlVAEBgcxS5di5s3DtLZiduzANDVRVITgSgiuhOBKmCEvXmCuXcP09w+jqqrSqO5uTH09RUsIroTgSgiuhBnS14fZvx8zOppGrVuHqa9nVhCCKyG4EoIroZAGBlCbKv5CXXzyDurLL+6g/pzfwmwjBFdCcCUEV0IhnT6N6ehAralnQmkNqrqaWUcIroTgSgiuhEJatAizYAEmx4TqamYzIbgSgishuBIKae9ezNgYKkmYUFLCbCYEV0JwJQRXQiHV1DCZDP8fQnAlBFdCcPUfZaDIbeMVzvAAAAAASUVORK5C\">"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "using VisionHeatmaps\n",
    "\n",
    "heatmap(input, analyzer)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "LRP's strength lies in assigning different rules to different layers,\n",
    "based on their functionality in the neural network[^1].\n",
    "RelevancePropagation.jl implements many LRP rules out of the box,\n",
    "but it is also possible to *implement custom rules*.\n",
    "\n",
    "To assign different rules to different layers,\n",
    "use one of the composites presets,\n",
    "or create your own composite, as described in\n",
    "*Assigning rules to layers*."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Composite(\n  GlobalTypeMap(  \u001b[90m# all layers\u001b[39m\n\u001b[94m    Flux.Conv              \u001b[39m => \u001b[33mZPlusRule()\u001b[39m,\n\u001b[94m    Flux.ConvTranspose     \u001b[39m => \u001b[33mZPlusRule()\u001b[39m,\n\u001b[94m    Flux.CrossCor          \u001b[39m => \u001b[33mZPlusRule()\u001b[39m,\n\u001b[94m    Flux.Dense             \u001b[39m => \u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n\u001b[94m    Flux.Scale             \u001b[39m => \u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n\u001b[94m    Flux.LayerNorm         \u001b[39m => \u001b[33mLayerNormRule()\u001b[39m,\n\u001b[94m    typeof(NNlib.dropout)  \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    Flux.AlphaDropout      \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    Flux.Dropout           \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    Flux.BatchNorm         \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    typeof(Flux.flatten)   \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    typeof(MLUtils.flatten)\u001b[39m => \u001b[33mPassRule()\u001b[39m,\n\u001b[94m    typeof(identity)       \u001b[39m => \u001b[33mPassRule()\u001b[39m,\n ),\n  FirstLayerTypeMap(  \u001b[90m# first layer\u001b[39m\n\u001b[94m    Flux.Conv         \u001b[39m => \u001b[33mFlatRule()\u001b[39m,\n\u001b[94m    Flux.ConvTranspose\u001b[39m => \u001b[33mFlatRule()\u001b[39m,\n\u001b[94m    Flux.CrossCor     \u001b[39m => \u001b[33mFlatRule()\u001b[39m,\n ),\n)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "composite = EpsilonPlusFlat() # using composite preset EpsilonPlusFlat"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LRP(\n  Conv((5, 5), 1 => 6, relu) \u001b[90m => \u001b[39m\u001b[33mFlatRule()\u001b[39m,\n  MaxPool((2, 2))            \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Conv((5, 5), 6 => 16, relu)\u001b[90m => \u001b[39m\u001b[33mZPlusRule()\u001b[39m,\n  MaxPool((2, 2))            \u001b[90m => \u001b[39m\u001b[33mZeroRule()\u001b[39m,\n  Flux.flatten               \u001b[90m => \u001b[39m\u001b[33mPassRule()\u001b[39m,\n  Dense(256 => 120, relu)    \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n  Dense(120 => 84, relu)     \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n  Dense(84 => 10)            \u001b[90m => \u001b[39m\u001b[33mEpsilonRule{Float32}(1.0f-6)\u001b[39m,\n)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "analyzer = LRP(model, composite)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "28×28 Array{RGB{Float64},2} with eltype ColorTypes.RGB{Float64}:\n RGB{Float64}(0.999747,0.999747,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(0.999747,0.999747,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.998783,0.998783)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.998783,0.998783)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.996432,0.996432)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.99618,0.99618)    …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.995426,0.995426)     RGB{Float64}(1.0,0.99838,0.99838)\n RGB{Float64}(1.0,0.996895,0.996895)     RGB{Float64}(1.0,0.99838,0.99838)\n RGB{Float64}(1.0,0.997046,0.997046)     RGB{Float64}(1.0,0.996647,0.996647)\n RGB{Float64}(1.0,0.999397,0.999397)     RGB{Float64}(1.0,0.996647,0.996647)\n ⋮                                    ⋱  \n RGB{Float64}(0.99874,0.99874,1.0)       RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(0.999507,0.999507,1.0)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(0.999796,0.999796,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(0.999804,0.999804,1.0)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.999226,0.999226)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.999226,0.999226)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.999993,0.999993)  …  RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,0.999993,0.999993)     RGB{Float64}(1.0,1.0,1.0)\n RGB{Float64}(1.0,1.0,1.0)               RGB{Float64}(1.0,1.0,1.0)",
      "image/png": "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",
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "heatmap(input, analyzer)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing layerwise relevances\n",
    "If you are interested in computing layerwise relevances,\n",
    "call `analyze` with an LRP analyzer and the keyword argument\n",
    "`layerwise_relevances=true`.\n",
    "\n",
    "The layerwise relevances can be accessed in the `extras` field\n",
    "of the returned `Explanation`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(Float32[-1.5046089f-6 -1.5046089f-6 … 4.4148962f-8 0.0; -1.5046089f-6 -1.5046089f-6 … 4.4148962f-8 0.0; … ; 6.1168203f-6 6.1168203f-6 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;;], Float32[-3.7615224f-5 0.0 … 1.103724f-6 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0001529205 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;;], Float32[-3.7615224f-5 0.00021888175 … 0.000114222385 1.103724f-6; 0.00018855373 0.00027439542 … 0.00020195934 -3.4702516f-5; … ; -2.6229336f-5 7.008412f-5 … -2.8691686f-6 0.0; 0.0001529205 0.00029437395 … 0.0 0.0;;; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 -0.0; 0.0 0.0 … -0.0 0.0;;; -0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; -0.0 0.0 … 0.0 0.0;;; -0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; -0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0;;; 0.0 -0.0 … -0.0 0.0; -0.0 0.0 … 0.0 0.0; … ; 0.0 -0.0 … -0.0 0.0; 0.0 0.0 … -0.0 0.0;;; 0.0 -0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 -0.0; 0.0 0.0 … 0.0 0.0;;;;], Float32[0.0 0.0 … 0.0 0.0; -0.0027488603 0.0 … 0.02671153 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.03954778 0.0 … 0.0 -0.0014172087;;; -0.0014038438 0.0 … 0.0 -0.00047513167; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.004709776 … 0.0 0.0;;; 0.0 0.0 … 0.0 -0.002364168; 0.0 0.0 … 0.0 0.0; … ; 0.00063266495 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 -0.014013007; 0.0 0.014055459 … 0.0 0.0; … ; 0.0 0.0 … -0.00013713303 0.0; 0.037856653 0.0 … 0.0 0.0;;; -0.0033661663 0.0 … 0.008260983 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.01444692 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 -0.038602687; … ; 0.0 0.0014011612 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;;], Float32[-0.0027488603 -0.0 0.0006903657 0.02671153; -0.0043666936 -0.01234732 0.0 -0.013395859; -0.010977116 0.04276983 -0.0 -9.9327546f-5; 0.03954778 0.0 -0.0 -0.0014172087;;; -0.0014038438 0.017887121 0.0 -0.0004751317; -0.0 0.016042996 -0.0 -0.0; 0.011004027 0.0 -0.0 -0.0; 0.004709776 -0.009777178 -0.0 0.0;;; -0.0 -0.025314394 -0.011204087 -0.002364168; 0.027246127 -0.016887693 0.0 -0.010472963; 0.00095062767 -0.00031839436 -0.022801049 0.0036320935; 0.00063266495 -0.0028789637 0.011017141 0.0;;; … ;;; 0.014055459 0.011828159 -0.0 -0.014013007; 0.01990776 0.017337693 -0.0001569362 -0.0; -0.011918854 -0.00459134 0.0 -0.004262696; 0.037856653 0.023232974 0.0 -0.00013713304;;; -0.0033661663 -0.0 0.01047569 0.008260983; -0.0 0.010837908 0.06946186 0.0038659107; 0.0 -0.0063336077 0.029801883 0.02022359; -0.0 -0.001508267 -0.0047802655 0.01444692;;; -0.0 0.060284954 0.0021190182 -0.038602687; -0.0 0.0 0.015209901 0.0; -0.037314404 0.0054231985 0.0 0.0; 0.0014011612 0.0 0.0 0.0;;;;], Float32[-0.0027488603; -0.0043666936; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; -0.0; 0.0;;], Float32[0.028250216; 0.026568355; … ; -0.0; 0.032229893;;], Float32[0.0; 0.0; … ; 0.0; 1.0;;])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "expl = analyze(input, analyzer; layerwise_relevances=true)\n",
    "expl.extras.layerwise_relevances"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the layerwise relevances are only kept for layers in the outermost `Chain` of the model.\n",
    "Since we used a flattened model, we obtained all relevances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance tips\n",
    "### Using LRP with a GPU\n",
    "All LRP analyzers support GPU backends,\n",
    "building on top of [Flux.jl's GPU support](https://fluxml.ai/Flux.jl/stable/gpu/).\n",
    "Using a GPU only requires moving the input array and model weights to the GPU.\n",
    "\n",
    "For example, using [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```julia\n",
    "using CUDA, cuDNN\n",
    "using Flux\n",
    "using RelevancePropagation\n",
    "\n",
    "# move input array and model weights to GPU\n",
    "input = input |> gpu # or gpu(input)\n",
    "model = model |> gpu # or gpu(model)\n",
    "\n",
    "# analyzers don't require calling `gpu`\n",
    "analyzer = LRP(model)\n",
    "\n",
    "# explanations are computed on the GPU\n",
    "expl = analyze(input, analyzer)\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some operations, like saving, require moving explanations back to the CPU.\n",
    "This can be done using Flux's `cpu` function:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```julia\n",
    "val = expl.val |> cpu # or cpu(expl.val)\n",
    "\n",
    "using BSON\n",
    "BSON.@save \"explanation.bson\" val\n",
    "```\n",
    "\n",
    "### Using LRP without a GPU\n",
    "Using Julia's package extension mechanism,\n",
    "RelevancePropagation.jl's LRP implementation can optionally make use of\n",
    "[Tullio.jl](https://github.com/mcabbott/Tullio.jl) and\n",
    "[LoopVectorization.jl](https://github.com/JuliaSIMD/LoopVectorization.jl)\n",
    "for faster LRP rules on dense layers.\n",
    "\n",
    "This only requires loading the packages before loading RelevancePropagation.jl:\n",
    "```julia\n",
    "using LoopVectorization, Tullio\n",
    "using RelevancePropagation\n",
    "```\n",
    "\n",
    "[^1]: G. Montavon et al., [Layer-Wise Relevance Propagation: An Overview](https://link.springer.com/chapter/10.1007/978-3-030-28954-6_10)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
